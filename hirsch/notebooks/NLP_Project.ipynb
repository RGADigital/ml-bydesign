{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# R/GA by Design Hackday - Beyond Rules with NLP\n",
    "\n",
    "Thanks for choosing the Natural Language Processing project! This notebook will serve as your guide during your project. \n",
    "\n",
    "\n",
    "## Contents\n",
    "* Goals\n",
    "* Agenda\n",
    "* Introductory concepts in NLP\n",
    "* Data processing for supplied corpora.\n",
    "* Step by step guide to sentence classification (sentiment analysis).\n",
    "* preliminary examples for topic modelling using LDA.\n",
    "\n",
    "## Goals:\n",
    "* Learn how to create a problem statement and an execution plan.\n",
    "* Familiarize yourself with the basic concepts, challenges, opportunities, and methods of NLP.\n",
    "* Understand how NLP can be used in your work.\n",
    "* Collectively spec a prototype.\n",
    "\n",
    "\n",
    "## Agenda\n",
    "\n",
    "#### What is NLP?  (60 minutes):\n",
    "\n",
    "* Deck (20 min) - technical / landscape\n",
    "* Examples (20 min) - play around with example applications.\n",
    "* Reflect - What role does text play in your work and how can NLP support this? (10 min)\n",
    "  * how do you use text in your work?\n",
    "  * how could this be relevant?\n",
    "  * how can this technological affordance be used for something innovative? \n",
    "* Read through and discuss introductory material around NLP concepts. (10 min)\n",
    "* Clone the repo or download the repo as a zip, alternatively read docs online.\n",
    "  * If you do not have admin rights, find someone on your team who does or follow along with Michael.\n",
    "\n",
    "#### Project Planning (30+30+45 minutes):\n",
    "\n",
    "* Brainstorm (30 min) - Put together a bunch of ideas - from simple to moonshot.\n",
    "* Present (30 min) - Present 3 best ideas to the group.\n",
    "  * discuss with others around feasibility.\n",
    "  * settle on 1 idea.\n",
    "* Nail down a brief and an execution plan. (20 min)\n",
    "  * Detail what you will and *wont* do.\n",
    "* Gather inspirational material from personal archives or included resources list. (5 min)\n",
    "* Dole out tasks, consult with Michael on what it will take to build this thing. (20 min)\n",
    "* Thing to consider:\n",
    "  * Who do you need on your team?\n",
    "  * Why is NLP an important ingredient in your solution?\n",
    "  * What data do you need to get started?\n",
    "  * How is the technology manifested in the deliverable?\n",
    "\n",
    "#### Working (40+10+40 minutes):\n",
    "\n",
    "* Working session (40 min)\n",
    "* \"Client\" Review (10 min)\n",
    "* Working session (40 min)\n",
    "\n",
    "#### Wrap-up and presentation gathering (15 min)\n",
    "* Prepare for 17:15 regroup with the larger group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.corpus import inaugural\n",
    "\n",
    "pd.options.display.max_colwidth = 0\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introductory Concepts in NLP\n",
    "\n",
    "## Data\n",
    "This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\n",
    "\n",
    "It contains sentences labelled with positive or negative sentiment, extracted from reviews of products, movies, and restaurants\n",
    "\n",
    "**Format**:\n",
    "* sentence \\t score \\n\n",
    "\n",
    "**Details**:\n",
    "* Score is either 1 (for positive) or 0 (for negative)\t\n",
    "* The sentences come from three different websites/fields:\n",
    "  * imdb.com\n",
    "  * amazon.com\n",
    "  * yelp.com\n",
    "\n",
    "For each website, there are 500 positive and 500 negative sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "reviews_df = pd.DataFrame(columns = [\"review\", \"sentiment\", \"source\"])\n",
    "\n",
    "# load the three datasets into the empty dataframe\n",
    "for dirpath, _, filenames in os.walk(\"../data/web-reviews/\"):\n",
    "    for filename in filenames:\n",
    "        data = pd.read_table(dirpath + filename, names = [\"review\",\"sentiment\"])\n",
    "        source = filename.split(\"_\")[0]\n",
    "        data[\"source\"] = source\n",
    "        reviews_df = reviews_df.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our data looks. First, we print a random sample of the reviews table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>I'll be drivng along, and my headset starts ringing for no reason.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>They were golden-crispy and delicious.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Not much flavor to them, and very poorly constructed.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>- They never brought a salad we asked for.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Rip off---- Over charge shipping.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 review  \\\n",
       "370  I'll be drivng along, and my headset starts ringing for no reason.   \n",
       "804  They were golden-crispy and delicious.                               \n",
       "653  Not much flavor to them, and very poorly constructed.                \n",
       "26   - They never brought a salad we asked for.                           \n",
       "329  Rip off---- Over charge shipping.                                    \n",
       "\n",
       "     sentiment  \\\n",
       "370  0.0         \n",
       "804  1.0         \n",
       "653  0.0         \n",
       "26   0.0         \n",
       "329  0.0         \n",
       "\n",
       "     source  \n",
       "370  amazon  \n",
       "804  yelp    \n",
       "653  yelp    \n",
       "26   yelp    \n",
       "329  amazon  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets look at some of the capabilities of **TextBlob**, a python library for text processing.\n",
    "\n",
    "First, we will see how we can use TextBlob to get simple information out of a single review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob(\"Bad characters, bad story and bad acting.  \")\n",
      "\n",
      "\n",
      "[   ('Bad', u'NNP'),\n",
      "    ('characters', u'NNS'),\n",
      "    ('bad', u'JJ'),\n",
      "    ('story', u'NN'),\n",
      "    ('and', u'CC'),\n",
      "    ('bad', u'JJ'),\n",
      "    ('acting', u'NN')]\n",
      "\n",
      "\n",
      "WordList([u'bad story'])\n",
      "\n",
      "\n",
      "Sentiment(polarity=-0.5249999999999999, subjectivity=0.5)\n"
     ]
    }
   ],
   "source": [
    "#take a random review and turn it into a textblob\n",
    "text = reviews_df.sample(1).iloc[0][\"review\"]\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# print some information about the blob\n",
    "pp.pprint(blob)\n",
    "print(\"\\n\")\n",
    "pp.pprint(blob.tags)\n",
    "print(\"\\n\")\n",
    "pp.pprint(blob.noun_phrases)\n",
    "print(\"\\n\")\n",
    "pp.pprint(blob.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look at some tools that will allow use to standardize sentences and words.\n",
    "\n",
    "**Lemmas** \n",
    "Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad > Bad\n",
      "characters > character\n",
      "bad > bad\n",
      "story > story\n",
      "and > and\n",
      "bad > bad\n",
      "acting > acting\n"
     ]
    }
   ],
   "source": [
    "# Show words and their lemmas.\n",
    "for word in blob.words:\n",
    "    w = Word(word)\n",
    "    print word, \">\",w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad > [Synset('bad.n.01')]\n",
      "characters > [Synset('fictional_character.n.01')]\n",
      "bad > [Synset('bad.n.01')]\n",
      "story > [Synset('narrative.n.01')]\n",
      "and > []\n",
      "bad > [Synset('bad.n.01')]\n",
      "acting > [Synset('acting.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# show words and \n",
    "for word in blob.words:\n",
    "    w = Word(word)\n",
    "    print w, \">\", w.synsets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling Using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
