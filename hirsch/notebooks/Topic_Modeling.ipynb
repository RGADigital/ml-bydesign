{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic Modelling Presidential Inaugural Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from nltk.corpus import stopwords, inaugural\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_colwidth = 50\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data\n",
    "The dataset we will use for topic modelling will be the presidential inaugural addresses, from George Washington to Barack Obama (2009)\n",
    "\n",
    "The first thing we will do is process the raw speeches, and then putting them into a dataframe (think a database table). The dataframe will contain metadata about the speeches - year, historical era, and the president's name.\n",
    "\n",
    "Our `process` function does a few key things:\n",
    "* Filters out **stopwords**, which typically refers to the most common words in a language. e.g. \"the\", \"is\", \"at\", ...\n",
    "* Filters out punctuation and numbers.\n",
    "* Makes sure that no empty strings are present.\n",
    "* makes every word lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this will allow us to map inaugural years to historical eras.\n",
    "def historical_era(year):\n",
    "    if year < 1830:\n",
    "        return \"Early Republic\"\n",
    "    elif year < 1854:\n",
    "        return \"Jacksonian Democracy\"\n",
    "    elif year < 1882:\n",
    "        return \"Sectional Conflict\"\n",
    "    elif year < 1898:\n",
    "        return \"Gilded Age\"\n",
    "    elif year < 1923:\n",
    "        return \"Progressive Era\"\n",
    "    elif year < 1962:\n",
    "        return \"Depression and World Conflict\"\n",
    "    elif year < 1990:\n",
    "        return \"Social Change and Soviet Relations\"\n",
    "    else:\n",
    "        return \"Globalization\"\n",
    "    \n",
    "def process(speech):\n",
    "    stoplist = set(stopwords.words())\n",
    "    return [re.sub(r'--|;|:|\\(|\\.|\\,|\\)|[0-9]*',\"\", word) for word in speech.lower().split() if word not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_speeches = [inaugural.raw(fileid) for fileid in inaugural.fileids()]\n",
    "years = [int(fileid[:4]) for fileid in inaugural.fileids()]\n",
    "presidents = [fileid.split(\"-\")[1].replace(\".txt\",\"\") for fileid in inaugural.fileids()]\n",
    "\n",
    "# strip out stopwords \n",
    "speeches = [process(speech) for speech in raw_speeches]\n",
    "speeches = [[word for word in speech if word !=\"\"]for speech in speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(zip(raw_speeches,speeches, years, presidents), columns = [\"raw_speech\",\"speech\", \"year\", \"president\"])\n",
    "speeches_df[\"era\"] = speeches_df[\"year\"].apply(historical_era) \n",
    "\n",
    "# we will use this later when analyzing how topics change over the course of time.\n",
    "eras = list(set(list(speeches_df[\"era\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see what our dataframe looks like. \n",
    "\n",
    "| raw_speech | speech | year | president | era |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| exact speech | processed text | year of speech | speaker | historical era |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_speech</th>\n",
       "      <th>speech</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fellow-Citizens of the Senate and of the House...</td>\n",
       "      <td>[fellow-citizens, senate, house, representativ...</td>\n",
       "      <td>1789</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Early Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fellow citizens, I am again called upon by the...</td>\n",
       "      <td>[fellow, citizens, called, upon, voice, countr...</td>\n",
       "      <td>1793</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Early Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When it was first perceived, in early times, t...</td>\n",
       "      <td>[first, perceived, early, times, middle, cours...</td>\n",
       "      <td>1797</td>\n",
       "      <td>Adams</td>\n",
       "      <td>Early Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friends and Fellow Citizens:\\n\\nCalled upon to...</td>\n",
       "      <td>[friends, fellow, citizens, called, upon, unde...</td>\n",
       "      <td>1801</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Early Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Proceeding, fellow citizens, to that qualifica...</td>\n",
       "      <td>[proceeding, fellow, citizens, qualification, ...</td>\n",
       "      <td>1805</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Early Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          raw_speech  \\\n",
       "0  Fellow-Citizens of the Senate and of the House...   \n",
       "1  Fellow citizens, I am again called upon by the...   \n",
       "2  When it was first perceived, in early times, t...   \n",
       "3  Friends and Fellow Citizens:\\n\\nCalled upon to...   \n",
       "4  Proceeding, fellow citizens, to that qualifica...   \n",
       "\n",
       "                                              speech  year   president  \\\n",
       "0  [fellow-citizens, senate, house, representativ...  1789  Washington   \n",
       "1  [fellow, citizens, called, upon, voice, countr...  1793  Washington   \n",
       "2  [first, perceived, early, times, middle, cours...  1797       Adams   \n",
       "3  [friends, fellow, citizens, called, upon, unde...  1801   Jefferson   \n",
       "4  [proceeding, fellow, citizens, qualification, ...  1805   Jefferson   \n",
       "\n",
       "              era  \n",
       "0  Early Republic  \n",
       "1  Early Republic  \n",
       "2  Early Republic  \n",
       "3  Early Republic  \n",
       "4  Early Republic  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "Next, we will transform all of our speeches using a document representation called **bag-of-words**. \n",
    "\n",
    "In this representation, each document is represented by one vector where each vector element represents a question-answer pair, in the style of:\n",
    "\n",
    ">“How many times does the word *protest* appear in the document? Once.”\n",
    "\n",
    "It is advantageous to represent the questions only by their (integer) ids. The mapping between the questions and ids is called a dictionary.\n",
    "\n",
    "We see that after filtering out stopwords, and in/frequent words, we are left with a vocabulary consisting of unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(4934 unique tokens: [u'aided', u'limited', u'dissolution', u'comparatively', u'desirable']...)\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary that maps words to integers.\n",
    "dictionary = gensim.corpora.Dictionary(speeches)\n",
    "\n",
    "# filter out really frequent and infrequent words\n",
    "dictionary.filter_extremes(no_below=2)\n",
    "\n",
    "dictionary.save(\"../data/reviews.dict\")\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection\n",
    "\n",
    ">What are the 3 most common words in Washington's first inaugural address? How about Obama's 2009 address?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, 1789:  [(u'me', 5), (u'ought', 4), (u'nature', 3)]\n",
      "Obama, 2009:  [(u'america', 7), (u'today', 6), (u'cannot', 6)]\n"
     ]
    }
   ],
   "source": [
    "print \"Washington, 1789: \", pp.pformat([(dictionary[word[0]], word[1]) for word in sorted(dictionary.doc2bow(speeches[0]), key=lambda x: x[1], reverse=True)[:3]])\n",
    "print \"Obama, 2009: \", pp.pformat([(dictionary[word[0]], word[1]) for word in sorted(dictionary.doc2bow(speeches[-1]), key=lambda x: x[1], reverse=True)[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our dictionary, we can now convert each document into it's **bag-of-words** representation and save the collection of these vectors as our corpus. Each entry in our corpus will indicate which words from our dictioary appear in the address, and how often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Words - Obama, 2009\n",
      "Bag-of-Words:  [   (32, 3),\n",
      "    (37, 1),\n",
      "    (41, 1),\n",
      "    (44, 1),\n",
      "    (57, 1),\n",
      "    (71, 1),\n",
      "    (72, 2),\n",
      "    (76, 1),\n",
      "    (82, 3),\n",
      "    (112, 1)]\n",
      "Processed:  [   u'carried',\n",
      "    u'emerged',\n",
      "    u'oceans',\n",
      "    u'homes',\n",
      "    u'cause',\n",
      "    u'enjoy',\n",
      "    u'charter',\n",
      "    u'tolerate',\n",
      "    u'across',\n",
      "    u'join']\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(speech) for speech in speeches]\n",
    "gensim.corpora.MmCorpus.serialize(\"../data/reviews.mm\", corpus)\n",
    "print \"First 10 Tokens - Obama, 2009\"\n",
    "print \"Bag-of-Words: \", pp.pformat(corpus[-1][:10])\n",
    "print \"Processed: \", pp.pformat([dictionary[id] for id,_ in corpus[-1][:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "\n",
    "We are now equipped to perform topic modelling on the speeches. However, our current corpus treats all words equally. That is, all terms carry equal weight across all of the speeches. We apply another transformation called **td-idf** (term frequency - inverse document frequency) which will update the weights of each word so as to capture how important it is to the speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "# corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our td-idf representation, we will perform **Latent Dirichlet Allocation (LDA)**, which will allow us to discover topics in the inaugural speeches. \n",
    "\n",
    "The model outputs a series of \"topics\" which are comprised of words and weights corresponding to the \"influence\" that word has on the topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (9, u'0.001*\"executive\" + 0.001*\"congress\" + 0.001*\"subject\"'),\n",
      "    (25, u'0.006*\"clothed\" + 0.004*\"housed\" + 0.004*\"fed\"'),\n",
      "    (7, u'0.009*\"sides\" + 0.008*\"pledge\" + 0.006*\"ask\"'),\n",
      "    (11, u'0.012*\"democracy\" + 0.006*\"america\" + 0.006*\"will\"'),\n",
      "    (17, u'0.002*\"america\" + 0.002*\"congress\" + 0.001*\"executive\"'),\n",
      "    (24, u'0.006*\"address\" + 0.005*\"neither\" + 0.005*\"slaves\"'),\n",
      "    (18, u'0.001*\"executive\" + 0.001*\"congress\" + 0.001*\"general\"'),\n",
      "    (21, u'0.004*\"congress\" + 0.003*\"republic\" + 0.003*\"general\"'),\n",
      "    (16, u'0.007*\"america\" + 0.006*\"today\" + 0.004*\"things\"'),\n",
      "    (26, u'0.014*\"america\" + 0.014*\"responsibility\" + 0.010*\"abroad\"')]\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus, id2word = dictionary, num_topics = 30, passes=4)\n",
    "corpus_lda = lda[corpus_tfidf]\n",
    "\n",
    "# print 10 of our 30 topics.\n",
    "pp.pprint(lda.print_topics(10, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to inspect the topic that each of the documents belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington , 1793\n",
      "[(4, 0.97156862745096717)]\n",
      "u'0.006*\"false\" + 0.006*\"reason\" + 0.005*\"limits\" + 0.005*\"due\" + 0.005*\"press\" + 0.005*\"therefore\" + 0.004*\"measures\" + 0.004*\"truth\" + 0.004*\"expenses\" + 0.004*\"revenue\"'\n"
     ]
    }
   ],
   "source": [
    "check = 1\n",
    "print speeches_df.iloc[check][\"president\"], \",\", speeches_df.iloc[check][\"year\"]\n",
    "print sorted(lda.get_document_topics(corpus[check]), key = lambda x: x[1], reverse=True)\n",
    "print pp.pformat(lda.print_topic(22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '1789-Washington': {   'topics': 1},\n",
      "    '1793-Washington': {   'topics': 1},\n",
      "    '1797-Adams': {   'topics': 1},\n",
      "    '1801-Jefferson': {   'topics': 1},\n",
      "    '1805-Jefferson': {   'topics': 1},\n",
      "    '1809-Madison': {   'topics': 2},\n",
      "    '1813-Madison': {   'topics': 1},\n",
      "    '1817-Monroe': {   'topics': 3},\n",
      "    '1821-Monroe': {   'topics': 3},\n",
      "    '1825-Adams': {   'topics': 3},\n",
      "    '1829-Jackson': {   'topics': 1},\n",
      "    '1833-Jackson': {   'topics': 2},\n",
      "    '1837-VanBuren': {   'topics': 5},\n",
      "    '1841-Harrison': {   'topics': 4},\n",
      "    '1845-Polk': {   'topics': 3},\n",
      "    '1849-Taylor': {   'topics': 1},\n",
      "    '1853-Pierce': {   'topics': 3},\n",
      "    '1857-Buchanan': {   'topics': 3},\n",
      "    '1861-Lincoln': {   'topics': 5},\n",
      "    '1865-Lincoln': {   'topics': 1},\n",
      "    '1869-Grant': {   'topics': 1},\n",
      "    '1873-Grant': {   'topics': 2},\n",
      "    '1877-Hayes': {   'topics': 2},\n",
      "    '1881-Garfield': {   'topics': 3},\n",
      "    '1885-Cleveland': {   'topics': 2},\n",
      "    '1889-Harrison': {   'topics': 6},\n",
      "    '1893-Cleveland': {   'topics': 2},\n",
      "    '1897-McKinley': {   'topics': 2},\n",
      "    '1901-McKinley': {   'topics': 2},\n",
      "    '1905-Roosevelt': {   'topics': 1},\n",
      "    '1909-Taft': {   'topics': 1},\n",
      "    '1913-Wilson': {   'topics': 1},\n",
      "    '1917-Wilson': {   'topics': 1},\n",
      "    '1921-Harding': {   'topics': 6},\n",
      "    '1925-Coolidge': {   'topics': 5},\n",
      "    '1929-Hoover': {   'topics': 4},\n",
      "    '1933-Roosevelt': {   'topics': 4},\n",
      "    '1937-Roosevelt': {   'topics': 1},\n",
      "    '1941-Roosevelt': {   'topics': 3},\n",
      "    '1945-Roosevelt': {   'topics': 1},\n",
      "    '1949-Truman': {   'topics': 1},\n",
      "    '1953-Eisenhower': {   'topics': 3},\n",
      "    '1957-Eisenhower': {   'topics': 3},\n",
      "    '1961-Kennedy': {   'topics': 1},\n",
      "    '1965-Johnson': {   'topics': 2},\n",
      "    '1969-Nixon': {   'topics': 1},\n",
      "    '1973-Nixon': {   'topics': 3},\n",
      "    '1977-Carter': {   'topics': 1},\n",
      "    '1981-Reagan': {   'topics': 2},\n",
      "    '1985-Reagan': {   'topics': 1},\n",
      "    '1989-Bush': {   'topics': 2},\n",
      "    '1993-Clinton': {   'topics': 1},\n",
      "    '1997-Clinton': {   'topics': 2},\n",
      "    '2001-Bush': {   'topics': 2},\n",
      "    '2005-Bush': {   'topics': 3},\n",
      "    '2009-Obama': {   'topics': 1}}\n"
     ]
    }
   ],
   "source": [
    "# check how many topics each speech belongs to\n",
    "topics_per_speech = {\n",
    "    str(speeches_df.iloc[i][\"year\"]) + \"-\" + str(speeches_df.iloc[i][\"president\"]) :{\n",
    "        \"topics\": len(lda.get_document_topics(corpus[i]))\n",
    "    }\n",
    "    for i, _ in enumerate(corpus)\n",
    "}\n",
    "\n",
    "pp.pprint(topics_per_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What happens if you split up the data by era and run an LDA on each of the eras separately? How do the topics change over time?\n",
    "2. Label the topics!\n",
    "3. Play around with parameters, how do the topics change?\n",
    "  * try filtering the dictionary differently.\n",
    "  * try changing the number of topics that you are hardcoding.\n",
    "4. How can you change the processing step to add more intelligent parsing of the speeches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing New Sentences, and Document Similarity.\n",
    "\n",
    "For those interested, you can read about further application of gensim here: https://radimrehurek.com/gensim/tut3.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim Link\n",
    "https://algobeans.com/2015/06/21/laymans-explanation-of-topic-modeling-with-lda-2/\n",
    "http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\n",
    "http://www.enchantedlearning.com/wordlist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
