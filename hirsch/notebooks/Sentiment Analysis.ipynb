{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "reviews_df = pd.DataFrame(columns = [\"review\", \"sentiment\", \"source\"])\n",
    "\n",
    "# load the three datasets into the empty dataframe\n",
    "for dirpath, _, filenames in os.walk(\"../data/web-reviews/\"):\n",
    "    for filename in filenames:\n",
    "        data = pd.read_table(dirpath + filename, names = [\"review\",\"sentiment\"])\n",
    "        source = filename.split(\"_\")[0]\n",
    "        data[\"source\"] = source\n",
    "        reviews_df = reviews_df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a random review and turn it into a textblob\n",
    "text = reviews_df.sample(1).iloc[0][\"review\"]\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# print some information about the blob\n",
    "pp.pprint(blob)\n",
    "print(\"\\n\")\n",
    "pp.pprint(blob.tags)\n",
    "print(\"\\n\")\n",
    "pp.pprint(blob.noun_phrases)\n",
    "print(\"\\n\")\n",
    "pp.pprint(blob.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look at some tools that will allow use to standardize sentences and words.\n",
    "\n",
    "**Lemmas** \n",
    "Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show words and their lemmas.\n",
    "for word in blob.words:\n",
    "    w = Word(word)\n",
    "    print word, \">\",w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show words and \n",
    "for word in blob.words:\n",
    "    w = Word(word)\n",
    "    print w, \">\", w.synsets[:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
